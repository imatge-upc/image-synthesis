import argparse, os, sys, glob, datetime, yaml
import torch
import time
import numpy as np
from tqdm import trange

from numpy import unravel_index
from omegaconf import OmegaConf
from PIL import Image
import itk
import matplotlib.pyplot as plt
from math import sqrt
from torchvision import transforms

from ldm.models.diffusion.ddim import DDIMSampler
from ldm.util import instantiate_from_config

rescale = lambda x: (x + 1.) / 2.

def adjust_dynamic_range(data, drange_in, drange_out):
    if drange_in != drange_out:
        scale = (np.float32(drange_out[1]) - np.float32(drange_out[0])) / (np.float32(drange_in[1]) - np.float32(drange_in[0]))
        bias = (np.float32(drange_out[0]) - np.float32(drange_in[0]) * scale)
        data = data * scale + bias
    return data

def custom_to_pil(x):
    x = x.detach().cpu()
    x = torch.clamp(x, -1., 1.)
    x = (x + 1.) / 2. #denormalize
    #x = (x * 204.36695600614223) + 145.4163783588631
    x = x.permute(1, 2, 0).numpy()
    x = (255 * x).astype(np.uint8)
    x = Image.fromarray(x)
    if not x.mode == "RGB":
        x = x.convert("RGB")
    return x

def rgb2gray(rgb):

    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]
    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b

    return gray
def inverse_normalization(img):
    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],
                                                     std = [ 1/145.4163783588631, 1/145.4163783588631, 1/145.4163783588631 ]),
                                transforms.Normalize(mean = [ -204.36695600614223, -204.36695600614223, -204.36695600614223 ],
                                                     std = [ 1., 1., 1. ]),
                               ])

    inv_img = invTrans(img)
    return inv_img

def custom_to_itk(x,f, n_saved, denom = False):
    x = x.detach().cpu()
    #f.write(f'{n_saved:03} original image generated by the network \n')
    #f.write(f'mean and std of image {x.mean()} and {x.std()}\n')
    v, indices = torch.min(x,0)
    v, indices = torch.min(v,0)
    v, indices = torch.min(v,0)
    min_x_original = v.item()
    v, indices = torch.max(x,0)
    v, indices = torch.max(v,0)
    v, indices = torch.max(v,0)
    max_x_original = v.item()
    #f.write(f'min {min_x_original} and max {max_x_original}\n')
    x = torch.clamp(x, -1., 1.)
    #f.write('after clamp to [-1,1]\n')
    #f.write(f'mean and std of image {x.mean()} and {x.std()}\n')
    if denom:
        #x = inverse_normalization(x)
        x = (x * 204.36695600614223) + 145.4163783588631
        #y = (inverse_normalization(torch.from_numpy(x).permute(2,0,1)).numpy).transpose(1,2,0)
        f.write('after de-normalize\n')
        f.write(f'mean and std of image {x.mean()} and {x.std()}\n')
        #f.write(f'mean and std of image {y.mean()} and {y.std()} and {y.shape}\n')
    
    #tranform to numpy to allow computing the min and max values
    x = x.numpy().transpose(1,2,0)
    #rgb to gray scale image
    x = rgb2gray(x)#.permute(1, 2, 0)
    #f.write('after RGB to Gray \n')
    #f.write(f'mean and std of image {x.mean()} and {x.std()}\n')
    #f.write('after tranform to numpy and transpose channel for h')
    #f.write(f'mean and std of image {x.mean()} and {x.std()}\n')
    
    x = itk.image_from_array(x)
    return x, min_x_original, max_x_original

def custom_to_np(x):
    # saves the batch in adm style as in https://github.com/openai/guided-diffusion/blob/main/scripts/image_sample.py
    sample = x.detach().cpu()
    #sample = ((sample + 1) * 127.5).clamp(0, 255).to(torch.uint8)
    sample = torch.clamp(sample,-1.,1.)
    sample = ((sample * 204.36695600614223) + 145.4163783588631).to(torch.float32)
    for i,s in enumerate(sample):
        x = s.numpy().transpose(1,2,0)
        #rgb to gray scale image
        x = rgb2gray(x)#.permute(1, 2, 0)
        sample[i] = torch.from_numpy(x)
    sample = sample.permute(0, 2, 3, 1)
    sample = sample.contiguous()
    return sample


def logs2pil(logs, keys=["sample"]):
    imgs = dict()
    for k in logs:
        try:
            if len(logs[k].shape) == 4:
                img = custom_to_pil(logs[k][0, ...])
            elif len(logs[k].shape) == 3:
                img = custom_to_pil(logs[k])
            else:
                print(f"Unknown format for key {k}. ")
                img = None
        except:
            img = None
        imgs[k] = img
    return imgs

def logs2itk(logs, keys=["sample"]):
    imgs = dict()
    for k in logs:
        try:
            if len(logs[k].shape) == 4:
                img = custom_to_itk(logs[k][0, ...])
            elif len(logs[k].shape) == 3:
                img = custom_to_itk(logs[k])
            else:
                print(f"Unknown format for key {k}. ")
                img = None
        except:
            img = None
        imgs[k] = img
    return imgs

@torch.no_grad()
def convsample(model, shape, return_intermediates=True,
               verbose=True,
               make_prog_row=False):


    if not make_prog_row:
        return model.p_sample_loop(None, shape,
                                   return_intermediates=return_intermediates, verbose=verbose)
    else:
        return model.progressive_denoising(
            None, shape, verbose=True
        )


@torch.no_grad()
def convsample_ddim(model, steps, shape, eta=1.0
                    ):
    ddim = DDIMSampler(model)
    bs = shape[0]
    shape = shape[1:]
    samples, intermediates = ddim.sample(steps, batch_size=bs, shape=shape, eta=eta, verbose=False,)
    return samples, intermediates


@torch.no_grad()
def make_convolutional_sample(model, batch_size, vanilla=False, custom_steps=None, eta=1.0,):


    log = dict()

    shape = [batch_size,
             model.model.diffusion_model.in_channels,
             model.model.diffusion_model.image_size,
             model.model.diffusion_model.image_size]

    with model.ema_scope("Plotting"):
        t0 = time.time()
        if vanilla:
            sample, progrow = convsample(model, shape,
                                         make_prog_row=True)
        else:
            sample, intermediates = convsample_ddim(model,  steps=custom_steps, shape=shape,
                                                    eta=eta)

        t1 = time.time()

    x_sample = model.decode_first_stage(sample)

    log["sample"] = x_sample
    log["time"] = t1 - t0
    log['throughput'] = sample.shape[0] / (t1 - t0)
    print(f'Throughput for this batch: {log["throughput"]}')
    return log

def run(model, logdir, denom, batch_size=50, vanilla=False, custom_steps=None, eta=None, n_samples=50000, nplog=None):
    if vanilla:
        print(f'Using Vanilla DDPM sampling with {model.num_timesteps} sampling steps.')
    else:
        print(f'Using DDIM sampling with {custom_steps} sampling steps and eta={eta}')

    
    tstart = time.time()
    n_saved = len(glob.glob(os.path.join(logdir,'*.png')))-1
    # path = logdir
    #g = open(imglogdir  + f'min_x_list.txt','w')
    #h = open(imglogdir  + f'max_x_list.txt','w')
    if model.cond_stage_model is None:
        all_images = []

        print(f"Running unconditional sampling for {n_samples} samples")
        for _ in trange(n_samples // batch_size, desc="Sampling Batches (unconditional)"):
            logs = make_convolutional_sample(model, batch_size=batch_size,
                                             vanilla=vanilla, custom_steps=custom_steps,
                                             eta=eta)
            #f = open(imglogdir  + f'{_}_sample_info.txt','w')
            n_saved = save_logs(logs, logdir, denom, n_saved=n_saved, key="sample")
            #n_saved = save_logs(logs, logdir, f, denom, n_saved=n_saved, key="sample")
            #f.close()
            all_images.extend([custom_to_np(logs["sample"])])
            if n_saved >= n_samples:
                print(f'Finish after generating {n_saved} samples')
                break
        all_img = np.concatenate(all_images, axis=0)
        all_img = all_img[:n_samples]
        shape_str = "x".join([str(x) for x in all_img.shape])
        nppath = os.path.join(nplog, f"{shape_str}-samples.npz")
        np.savez(nppath, all_img)
    else:
       raise NotImplementedError('Currently only sampling for unconditional models supported.')

    #g.close()
    #h.close()
    print(f"sampling of {n_saved} images finished in {(time.time() - tstart) / 60.:.2f} minutes.")


def save_logs(logs, path, denom=False, n_saved=0, key="sample", np_path=None):
    for k in logs:
        if k == key:
            batch = logs[key]
            if np_path is None:
                for x in batch:
                    #img = custom_to_pil(x)
                    #imgpath = os.path.join(path, f"{n_saved:03}.png")
                    #img.save(imgpath)
                    #saving as mha
                    img, min_x, max_x = custom_to_itk(x, n_saved, denom)
                    #g.write(f'{min_x} ')
                    #h.write(f'{max_x} ')
                    imgpath = os.path.join(path, f"{n_saved:06}.mha")
                    itk.imwrite(img, imgpath)
                    n_saved += 1
            """
            else:
                npbatch = custom_to_np(batch)
                shape_str = "x".join([str(x) for x in npbatch.shape])
                nppath = os.path.join(np_path, f"{n_saved}-{shape_str}-samples.npz")
                np.savez(nppath, npbatch)
                n_saved += npbatch.shape[0]
            """
    
    return n_saved


def get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-r",
        "--resume",
        type=str,
        nargs="?",
        help="load from logdir or checkpoint in logdir",
    )
    parser.add_argument(
        "-n",
        "--n_samples",
        type=int,
        nargs="?",
        help="number of samples to draw",
        default=50000
    )
    parser.add_argument(
        "-e",
        "--eta",
        type=float,
        nargs="?",
        help="eta for ddim sampling (0.0 yields deterministic sampling)",
        default=1.0
    )
    parser.add_argument(
        "-v",
        "--vanilla_sample",
        default=False,
        action='store_true',
        help="vanilla sampling (default option is DDIM sampling)?",
    )
    parser.add_argument(
        "-l",
        "--logdir",
        type=str,
        nargs="?",
        help="extra logdir",
        default="none"
    )
    parser.add_argument(
        "-c",
        "--custom_steps",
        type=int,
        nargs="?",
        help="number of steps for ddim and fastdpm sampling",
        default=50
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        nargs="?",
        help="the bs",
        default=10
    )
    parser.add_argument(
        "-d",
        "--denormalize",
        type=bool,
        nargs="?",
        help="apply denormalization to generated images",
        default=True
    )
    return parser


def load_model_from_config(config, sd):
    model = instantiate_from_config(config)
    model.load_state_dict(sd,strict=False)
    model.cuda()
    model.eval()
    return model


def load_model(config, ckpt, gpu, eval_mode):
    if ckpt:
        print(f"Loading model from {ckpt}")
        pl_sd = torch.load(ckpt, map_location="cpu")
        global_step = pl_sd["global_step"]
    else:
        pl_sd = {"state_dict": None}
        global_step = None
    model = load_model_from_config(config.model,
                                   pl_sd["state_dict"])

    return model, global_step


if __name__ == "__main__":
    now = datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
    sys.path.append(os.getcwd())
    command = " ".join(sys.argv)

    parser = get_parser()
    opt, unknown = parser.parse_known_args()
    ckpt = None

    if not os.path.exists(opt.resume):
        raise ValueError("Cannot find {}".format(opt.resume))
    if os.path.isfile(opt.resume):
        # paths = opt.resume.split("/")
        try:
            ckptdir = '/'.join(opt.resume.split('/')[:-1])
            logdir = opt.logdir
            # idx = len(paths)-paths[::-1].index("logs")+1
            print(f'Ckptdir is {ckptdir}')
        except ValueError:
            paths = opt.resume.split("/")
            idx = -2  # take a guess: path/to/logdir/checkpoints/model.ckpt
            logdir = "/".join(paths[:idx])
        ckpt = opt.resume
    else:
        assert os.path.isdir(opt.resume), f"{opt.resume} is not a directory"
        logdir = opt.resume.rstrip("/")
        ckpt = os.path.join(logdir, "model.ckpt")
    print(f'ckpt is: {ckpt}')
    
    print(f'logdir is: {logdir}')
    #base_configs = sorted(glob.glob(os.path.join(logdir, "config.yaml"))) 
    base_configs = sorted(glob.glob(os.path.join(logdir, 'configs', '*.yaml')))
    opt.base = base_configs
    #print(f"list of config not sorted {glob.glob(os.path.join(logdir, 'configs', '*.yaml'))}")
    #print(f'list of config files: {opt.base}\n')
    configs = [OmegaConf.load(cfg) for cfg in opt.base]
    cli = OmegaConf.from_dotlist(unknown)
    config = OmegaConf.merge(*configs, cli)

    gpu = True
    eval_mode = True
    if opt.logdir != "none":
        locallog = 'generated'
        if locallog == "": locallog = logdir.split(os.sep)[-2]
        print(f"Switching logdir from '{logdir}' to '{os.path.join(opt.logdir, locallog)}'")
        logdir = os.path.join(opt.logdir, locallog)
    

    #print(f'config: {config}')

    model, global_step = load_model(config, ckpt, gpu, eval_mode)
    print(f"global step: {global_step}")
    print(75 * "=")
    print("logging to:")
    
    if opt.vanilla_sample:
        logdir = os.path.join(logdir, f"{global_step:08}", f'eta_{opt.eta}_vanilla_denom_{opt.denormalize}')
    else:
        logdir = os.path.join(logdir, f"{global_step:08}", f'eta_{opt.eta}_ddim_{opt.custom_steps}_denom_{opt.denormalize}')
    imglogdir = os.path.join(logdir, "img")
    numpylogdir = os.path.join(logdir, "numpy")

    try:
        os.makedirs(imglogdir)
        os.makedirs(numpylogdir)
    except:
        imglogdir = imglogdir+'_1'
        numpylogdir = numpylogdir+'_1'
        os.makedirs(imglogdir)
        os.makedirs(numpylogdir)
    
    print(logdir)
    print(imglogdir)
    print(numpylogdir)
    print(75 * "=")

    # write config out
    sampling_file = os.path.join(logdir, "sampling_config.yaml")
    sampling_conf = vars(opt)

    with open(sampling_file, 'w') as f:
        yaml.dump(sampling_conf, f, default_flow_style=False)
    #print(sampling_conf)


    run(model, imglogdir, opt.denormalize, eta=opt.eta,
        vanilla=opt.vanilla_sample,  n_samples=opt.n_samples, custom_steps=opt.custom_steps,
        batch_size=opt.batch_size, nplog=numpylogdir)

    print("done.")
